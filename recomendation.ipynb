{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer = pd.read_csv('csv/Posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer.set_index('Id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = question_answer[question_answer['PostTypeId'] == 2]\n",
    "questions = question_answer[question_answer['PostTypeId'] == 1]\n",
    "# this observation has come from the fact that, PostTypeId == 2, have a parent Id, while those with 1 have answerCount field non empty, rest all ids are wikis etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answerer = answers.groupby('OwnerUserId')['ParentId'].apply(list).to_dict()\n",
    "answerer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_tags = questions['Tags'].apply(lambda x: list(filter(lambda x: x != '', x.split('|'))))\n",
    "question_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_tags = question_tags.explode()\n",
    "exploded_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = exploded_tags.value_counts()\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tag = tags.to_dict()\n",
    "count_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers.isna().sum()\n",
    "# 6822 answers are such that their owner is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_answers_per_user = answers['OwnerUserId'].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_answers_per_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! wrong code, gives very wrong answers, design is the most used tag\n",
    "\n",
    "# count_tag = dict()\n",
    "# for tags in question_tags:\n",
    "#   for tag in tags:\n",
    "#     if tag not in count_tag:\n",
    "#       count_tag[tag] = 0\n",
    "#     count_tag[tag] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_df = pd.read_csv('csv/Tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags_df.set_index('Id', inplace=True)\n",
    "tag_cols = tags_df.columns\n",
    "tag_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_tag_cols = ['Id', 'TagName']\n",
    "drop_cols = list(filter(lambda x: x not in req_tag_cols, tag_cols))\n",
    "drop_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tags_df = tags_df.drop(drop_cols, axis=1)\n",
    "new_tags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tags_df.set_index('TagName', inplace=True)\n",
    "new_tags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_dict = new_tags_df.to_dict()['Id']\n",
    "tag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tag = {tag_dict[k]: v for k, v in count_tag.items() if k in tag_dict} # some tags not there in the tags.csv file, don't know why :(\n",
    "# count_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answerer_table = pd.DataFrame(count_answers_per_user.items(), columns=['UserId', 'AnsweredQuestionCount'])\n",
    "answerer_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_table = pd.DataFrame(count_tag.items(), columns=['TagId', 'Count'])\n",
    "tags_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_tags_table = tags_table.sort_values(by='Count', ascending=False)\n",
    "sorted_tags_table.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_answerer_table = answerer_table.sort_values(by='AnsweredQuestionCount', ascending=False)\n",
    "sorted_answerer_table.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answerer_table = answerer_table[answerer_table['AnsweredQuestionCount'] >= threshold]\n",
    "answerer_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_table = tags_table[tags_table['Count'] >= threshold]\n",
    "tags_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tag_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tag_count = {}\n",
    "tags_table = tags_table.sort_values(['TagId'])\n",
    "answerer_table = answerer_table.sort_values(['UserId'])\n",
    "users = answerer_table['UserId'].values\n",
    "tags = tags_table['TagId'].values\n",
    "q_tag_map = question_tags.to_dict()\n",
    "\n",
    "\n",
    "for user in users:\n",
    "  tag_count = {tag : 0 for tag in tags}\n",
    "  for question in answerer[user]:\n",
    "    for tag in q_tag_map[question]:\n",
    "      try:\n",
    "        tag_count[tag_dict[tag]] += 1\n",
    "      except KeyError:\n",
    "        pass\n",
    "  user_tag_count[user] = tag_count\n",
    "del q_tag_map\n",
    "del users\n",
    "del tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tag_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert = pd.DataFrame.from_dict(user_tag_count, orient='index')\n",
    "del user_tag_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert.shape # 1163 users, 973 tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert = expert.map(lambda x: x/3 if x < 15 else 5)\n",
    "expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_matrix = expert.to_numpy()\n",
    "expert_shape = expert_matrix.shape\n",
    "expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_matrix[expert_matrix == 0] = np.nan\n",
    "np.isnan(expert_matrix).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start = (int(0.85 *expert_shape[0] ), int(0.85*expert_shape[1]))\n",
    "test_users, test_tags = test_start\n",
    "test_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matrix = np.copy(expert_matrix[test_users:, test_tags:])\n",
    "test_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = np.copy(expert_matrix)\n",
    "train_matrix[test_users:, test_tags:] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Report the following about your utility matrix:\n",
    "Summation value of the utility matrix\n",
    "Highest row sum of the utility matrix\n",
    "Highest column sum of the utility matrix\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sum_utility = np.nansum(expert_matrix)\n",
    "highest_row_sum = np.nansum(expert_matrix, axis = 0).max()\n",
    "highest_col_sum = np.nansum(expert_matrix, axis = 1).max()\n",
    "sum_utility, highest_row_sum, highest_col_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Report the following for your train and test data\n",
    "Summation value of the train matrix\n",
    "Dimension of the test matrix\n",
    "Summation value of test matrix\n",
    "\"\"\"\n",
    "\n",
    "sum_train = np.nansum(train_matrix)\n",
    "dim_test = test_matrix.shape\n",
    "sum_test = test_matrix.sum()\n",
    "sum_train, dim_test, sum_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourth Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users_start, test_tags_start = test_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "class CollaborativeFilter():\n",
    "  def __init__(self, utility_matrix, function='weighted'):\n",
    "    utility_zero_mask = utility_matrix == 0\n",
    "    utility_matrix[utility_zero_mask] = np.nan\n",
    "    self.utility_matrix = utility_matrix\n",
    "    self.utility_matrix_filled = utility_matrix.copy()\n",
    "    self.epsilon = 1e-9 # a small value to avoid division by zero\n",
    "    \n",
    "    self.final_rating_function = None\n",
    "    if function == 'weighted':\n",
    "      self.final_rating_function = self.weighted_average\n",
    "    elif function=='regular_average':\n",
    "      self.final_rating_function = self.average\n",
    "    else:\n",
    "      raise Exception(\"Function not allowed\")\n",
    "    \n",
    "  \n",
    "  def weighted_average(self, vector: np.ndarray, scores: np.ndarray):\n",
    "    return np.dot(vector, scores)/(np.sum(scores) + self.epsilon)\n",
    "  \n",
    "  def average(self, vector: np.ndarray, scores: np.ndarray):\n",
    "    return np.mean(vector)\n",
    "    \n",
    "\n",
    "  @abstractmethod\n",
    "  def predict(self):\n",
    "    pass\n",
    "  \n",
    "  \n",
    "  @abstractmethod\n",
    "  def compute_similarities(self):\n",
    "    pass\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserBasedCollaborativeFilter(CollaborativeFilter):\n",
    "    def __init__(self,expert_matrix ,k , function):\n",
    "      \"\"\"\n",
    "      utility_matrix : 2D numpy array\n",
    "      k : int\n",
    "      \n",
    "      k is the number of similar users to consider for prediction\n",
    "      utility_matrix is the matrix of user ratings, nan filled with 0\n",
    "      \"\"\"\n",
    "      super().__init__(expert_matrix, function)\n",
    "      self.k = k\n",
    "    \n",
    "    def compute_similarities(self, user_vector : np.ndarray):\n",
    "      \"\"\"\n",
    "      user_vector : 1D numpy array\n",
    "      \"\"\"\n",
    "      # self.utility_matrix has each column as a user and each row as an item\n",
    "      utility_rating_means = np.nanmean(self.utility_matrix, axis=0)\n",
    "      user_rating_mean = np.nanmean(user_vector)\n",
    "      # subtract the mean rating of each user from their ratings\n",
    "      utility_matrix_centered = self.utility_matrix - utility_rating_means\n",
    "      \n",
    "      # compute the cosine similarity between user_vector and each user\n",
    "      user_vector_centered = user_vector - user_rating_mean\n",
    "      \n",
    "      # compute the norms of the vectors, which might have nans as well\n",
    "      user_vector_norm = np.sqrt(np.nansum(user_vector_centered**2))\n",
    "      utility_matrix_norm = np.sqrt(np.nansum(utility_matrix_centered**2, axis=1))\n",
    "      # compute the dot product between user_vector and each user\n",
    "      \n",
    "      dot_product = np.nansum(utility_matrix_centered *user_vector_centered, axis = 1)\n",
    "      # compute the cosine similarity\n",
    "      similarities = dot_product/(user_vector_norm * utility_matrix_norm + self.epsilon)\n",
    "      \n",
    "      return similarities\n",
    "    \n",
    "    def find_k_nearest_users(self, user_vector : np.ndarray, i: int):\n",
    "      \"\"\"\n",
    "      user_vector : 1D numpy array\n",
    "      \n",
    "      returns the indices of the k most similar users to user_vector\n",
    "      \"\"\"\n",
    "      \n",
    "      similarities = self.compute_similarities(user_vector)\n",
    "      users_to_consider = np.where(~np.isnan(self.utility_matrix[:, i]))[0]\n",
    "      k = min(self.k, len(users_to_consider))\n",
    "      sorted_indices = np.argsort(similarities[users_to_consider])[-k:]\n",
    "      users_to_consider = users_to_consider[sorted_indices]\n",
    "      similarities = similarities[users_to_consider]\n",
    "      return similarities, users_to_consider\n",
    "    \n",
    "    \n",
    "    def predict(self, user_vector : np.ndarray, i: int):\n",
    "      \"\"\"\n",
    "      user_vector : 1D numpy array\n",
    "      i : int\n",
    "      \n",
    "      i is the index of the item to predict the rating for\n",
    "      \"\"\"\n",
    "      \n",
    "      # find the k most similar users who rated this item \n",
    "      similarities, users_to_consider = self.find_k_nearest_users(user_vector, i)\n",
    "      # similarity_scores = similarities[users_to_consider]\n",
    "      \n",
    "      # predict the rating for the item\n",
    "      prediction = self.final_rating_function(self.utility_matrix[users_to_consider, i], similarities)\n",
    "      return prediction\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_user_collaborator(train_matrix: np.ndarray, expert_matrix: np.ndarray, user_start: int, item_start: int, model: UserBasedCollaborativeFilter) -> float:\n",
    "    rmse_loss = 0\n",
    "    count = 0\n",
    "    for i in range(user_start, expert_matrix.shape[0]):\n",
    "        for j in range(item_start, expert_matrix.shape[1]):\n",
    "            if not np.isnan(expert_matrix[i, j]):\n",
    "                prediction = model.predict(train_matrix[i], j)\n",
    "                # print(prediction, i, j)\n",
    "                rmse_loss += (prediction - expert_matrix[i, j])**2\n",
    "                count += 1\n",
    "    rmse_loss = np.sqrt(rmse_loss/count)\n",
    "    \n",
    "    return rmse_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_cf = UserBasedCollaborativeFilter(train_matrix, 5, 'regular_average')\n",
    "# test_user_collaborator(train_matrix, expert_matrix, test_users_start, test_tags_start, user_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_cf = UserBasedCollaborativeFilter(train_matrix, 5, 'weighted')\n",
    "# test_user_collaborator(train_matrix, expert_matrix, test_users_start, test_tags_start, user_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ItemBasedCollaborativeFilter(CollaborativeFilter):\n",
    "    def __init__(self,expert_matrix ,k, function):\n",
    "      \"\"\"\n",
    "      utility_matrix : 2D numpy array\n",
    "      k : int\n",
    "      \n",
    "      k is the number of similar items to consider for prediction\n",
    "      utility_matrix is the matrix of user ratings, nan filled with 0\n",
    "      \"\"\"\n",
    "      super().__init__(expert_matrix, function)\n",
    "      self.k = k\n",
    "    \n",
    "    def compute_similarities(self, item_vector : np.ndarray):\n",
    "      \"\"\"\n",
    "      item_vector : 1D numpy array\n",
    "      \n",
    "      \"\"\"\n",
    "      # self.utility_matrix has each column as a user and each row as an item\n",
    "      utility_rating_means = np.nanmean(self.utility_matrix.T, axis=1)\n",
    "      item_rating_mean = np.nanmean(item_vector)\n",
    "      # subtract the mean rating of each user from their ratings\n",
    "      utility_matrix_centered = self.utility_matrix.T - utility_rating_means[:, np.newaxis]\n",
    "      \n",
    "      # compute the cosine similarity between item_vector and each item\n",
    "      item_vector_centered = item_vector - item_rating_mean\n",
    "      \n",
    "      # compute the norms of the vectors, which might have nans as well\n",
    "      item_vector_norm = np.sqrt(np.nansum(item_vector_centered**2))\n",
    "      utility_matrix_norm = np.sqrt(np.nansum(utility_matrix_centered**2, axis=1))\n",
    "      \n",
    "      # compute the dot product between item_vector and each item\n",
    "      dot_product = np.nansum(utility_matrix_centered *item_vector_centered, axis=1)\n",
    "      \n",
    "      # compute the cosine similarity\n",
    "      similarities = dot_product/(item_vector_norm * utility_matrix_norm + self.epsilon)\n",
    "      \n",
    "      return similarities\n",
    "    \n",
    "    \n",
    "    def find_k_nearest_items(self, item_vector : np.ndarray, u: int):\n",
    "      \"\"\"\n",
    "      item_vector : 1D numpy array\n",
    "      \n",
    "      returns the indices of the k most similar items to item_vector\n",
    "      \"\"\"\n",
    "      \n",
    "      similarities = self.compute_similarities(item_vector)\n",
    "      items_to_consider = np.where(~np.isnan(self.utility_matrix[u]))[0]\n",
    "      k = min(self.k, len(items_to_consider))\n",
    "      sorted_indices = np.argsort(similarities[items_to_consider])[-k:]\n",
    "      items_to_consider = items_to_consider[sorted_indices]\n",
    "      similarities = similarities[items_to_consider]\n",
    "      return similarities, items_to_consider\n",
    "    \n",
    "    \n",
    "    def predict(self, item_vector : np.ndarray, u: int):\n",
    "      \"\"\"\n",
    "      item_vector : 1D numpy array\n",
    "      u : int\n",
    "      u is the index of the user to predict the rating for\n",
    "      \"\"\"\n",
    "      similarity_scores, items_to_consider = self.find_k_nearest_items(item_vector, u)\n",
    "      \n",
    "      # predict the rating for the item\n",
    "      prediction = self.final_rating_function(self.utility_matrix[u, items_to_consider], similarity_scores)\n",
    "      return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_item_item_filter(train_matrix: np.ndarray, expert_matrix: np.ndarray, user_start: int, item_start: int, model: ItemBasedCollaborativeFilter) -> float:\n",
    "    rmse_loss = 0\n",
    "    count = 0\n",
    "    for i in range(user_start, expert_matrix.shape[0]):\n",
    "        for j in range(item_start, expert_matrix.shape[1]):\n",
    "            if not np.isnan(expert_matrix[i, j]):\n",
    "                prediction = model.predict(train_matrix[:, j], i)\n",
    "                # print(prediction, i, j)\n",
    "                rmse_loss += (prediction - expert_matrix[i, j])**2\n",
    "                count += 1\n",
    "    rmse_loss = np.sqrt(rmse_loss/count)\n",
    "    \n",
    "    return rmse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_cf = ItemBasedCollaborativeFilter(train_matrix, 5, 'weighted')\n",
    "# test_item_item_filter(train_matrix, expert_matrix, test_users_start, test_tags_start, item_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_cf = ItemBasedCollaborativeFilter(train_matrix, 5, 'regular_average')\n",
    "# test_item_item_filter(train_matrix, expert_matrix, test_users_start, test_tags_start, item_cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentFactorDecomposition:\n",
    "    def __init__(self, utility_matrix: np.ndarray, f : int, regp :int= 0, regq:int = 0):\n",
    "        \"\"\"\n",
    "        utility_matrix : 2D numpy array, Expert matrix\n",
    "        f : Number of Latent Factors\n",
    "        regp: regularization rate over p\n",
    "        regq: regularization rate over q\n",
    "        \"\"\"\n",
    "        self.utility_matrix = utility_matrix\n",
    "        self.f = f\n",
    "        self.epsilon = 1e-9\n",
    "        self.regp = regp\n",
    "        self.regq = regq\n",
    "        num_users, num_items = utility_matrix.shape\n",
    "        self.P = np.random.randn(num_users, f)/np.sqrt(num_users*f)\n",
    "        self.Q = np.random.randn(num_items, f)/np.sqrt(num_items*f)\n",
    "    \n",
    "    def predict(self, u, i):\n",
    "        return np.dot(self.P[u], self.Q[i])\n",
    "    \n",
    "    def train(self, epochs = 1000, thresh = 0.005, learn_start = 0.001):\n",
    "        \n",
    "        prev_loss = np.inf\n",
    "        alpha = learn_start\n",
    "        for epoch in range(epochs):\n",
    "            pred_matrix = np.dot(self.P, self.Q.T)\n",
    "            diffs = pred_matrix - self.utility_matrix\n",
    "            loss = np.nansum(diffs**2) + self.regp*np.nansum(self.P**2) + self.regq*np.nansum(self.Q**2)\n",
    "            \n",
    "            # applying SGD\n",
    "            p_reg_changes = 2*self.regp*self.P \n",
    "            q_reg_changes = 2*self.regq*self.Q\n",
    "            \n",
    "            \n",
    "            diffs[np.isnan(diffs)] = 0\n",
    "            # from observation each p[i,j] affects prediction of only user i for each item k. So, its SGD will get changes for user i and each item k.\n",
    "            p_rmse_changes = 2*(np.dot(diffs, self.Q))\n",
    "            # from observation each q[i,j] affects prediction of only item i for each user k. So, its SGD will get changes for item i and each user k.\n",
    "            q_rmse_changes = 2*(np.dot(diffs.T, self.P))\n",
    "            \n",
    "            self.P -= alpha*(p_rmse_changes + p_reg_changes)\n",
    "            self.Q -= alpha*(q_rmse_changes + q_reg_changes)\n",
    "            if(prev_loss - loss < thresh and prev_loss - loss > 0):\n",
    "                alpha /= 10\n",
    "            if epoch% 50 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{epochs} : Loss = {loss}\")\n",
    "            \n",
    "    def get_factors(self):\n",
    "        return self.P, self.Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lfd(model: LatentFactorDecomposition, expert_matrix: np.ndarray, user_start: int, item_start : int,f = 5):\n",
    "    rmse_loss = 0\n",
    "    count = 0\n",
    "    for i in range(user_start, expert_matrix.shape[0]):\n",
    "        for j in range(item_start, expert_matrix.shape[1]):\n",
    "            if not np.isnan(expert_matrix[i, j]):\n",
    "                prediction = model.predict(i, j)\n",
    "                # print(prediction, i, j)\n",
    "                rmse_loss += (prediction - expert_matrix[i, j])**2\n",
    "                count += 1\n",
    "    rmse_loss = np.sqrt(rmse_loss/count)\n",
    "    return rmse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LatentFactorDecomposition(train_matrix, f = 1)\n",
    "# model.train(epochs=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, learning is occuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_lfd(model, expert_matrix, test_users_start, test_tags_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to complete all deliverables for 4th part and 5th part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "from surprise import Dataset, Reader\n",
    "dataset_df = pd.DataFrame(train_matrix)\n",
    "long_df = dataset_df.stack().reset_index()\n",
    "long_df.columns = ['user_id', 'item_id', 'rating']\n",
    "# Define reader with rating scale (adjust if necessary)\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "\n",
    "# Load into Surprise dataset\n",
    "train_data = Dataset.load_from_df(long_df, reader)\n",
    "# Build the full training set\n",
    "trainset = train_data.build_full_trainset()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users_start, test_tags_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matrix = np.copy(expert_matrix)\n",
    "test_df = pd.DataFrame(test_matrix)\n",
    "test_long_df = test_df.stack().reset_index()\n",
    "test_long_df.columns = ['user_id', 'item_id', 'rating']\n",
    "test_df_final = test_long_df[(test_long_df['user_id'] >= test_users_start) & (test_long_df['item_id'] >= test_tags_start)].reset_index(drop=True)\n",
    "test_data = Dataset.load_from_df(test_df_final, reader)\n",
    "testset = [tuple(x) for x in test_df_final[['user_id', 'item_id', 'rating']].values]\n",
    "testset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "\n",
    "model = KNNBasic(sim_options = {'name': 'pearson', 'user_based': False}, k =5)\n",
    "model.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import accuracy\n",
    "predictions = model.test(testset)\n",
    "rmse = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, SVD\n",
    "\n",
    "algo = SVD()\n",
    "\n",
    "algo.fit(trainset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = algo.test(testset)\n",
    "\n",
    "# Then compute RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
